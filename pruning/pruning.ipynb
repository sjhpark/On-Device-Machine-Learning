{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from indiv_utils import load_yaml, size_on_disk, get_layers, \\\n",
    "                        measure_inference_latency, param_count, \\\n",
    "                        FLOPs_count, save_model_weights, start_train, \\\n",
    "                        check_buffers, sparse_representation, Sparsity, \\\n",
    "                        global_unstructured_pruning, accuracy\n",
    "from models import FFNN\n",
    "from data_processing import MNISTDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hyperparameter  | MNIST |\n",
    "| --------------- | ----- |\n",
    "| learning rate   | 0.001 |\n",
    "| batch size      | 64    |\n",
    "| hidden size     | 1024  |\n",
    "| # hidden layers | 2     |\n",
    "| input size      | 20x20 |\n",
    "| output size     | 10    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup\"\"\"\n",
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_hidden = 2\n",
    "hidden_dim = 1024\n",
    "out_dim = 10 # 10 MNIST classes   \n",
    "epochs = 2\n",
    "input_dim = 20*20\n",
    "\n",
    "# config\n",
    "config = load_yaml('config')\n",
    "\n",
    "# device \n",
    "device = torch.device(config['device'])\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model\n",
    "model = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model initialization:\n",
    "Before training, SAVE the model's initial (random) weights. \n",
    "You will use them later for iterative pruning.\"\"\"\n",
    "\n",
    "if os.path.exists(\"out/FFNN_weights_initial.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    initial_random_weights = save_model_weights(model, fname=\"initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "if os.path.exists(\"out/FFNN_weights_trained.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    start_train(model, device, criterion, epochs, batch_size, lr)\n",
    "    trained_weights = save_model_weights(model, fname=\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded initial model weights\n",
      "Loaded trained model weights\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "parsing test features...\n",
      "The number of test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load initial model\"\"\"\n",
    "model_initial = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_initial.load_state_dict(torch.load(\"out/FFNN_weights_initial.pth\"))\n",
    "print(\"Loaded initial model weights\")\n",
    "\n",
    "\"\"\"load trained model\"\"\"\n",
    "model_trained = copy.deepcopy(model_initial)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "print(\"Loaded trained model weights\")\n",
    "\n",
    "\"\"\"test dataset\"\"\"\n",
    "test_dataset = MNISTDataProcessor().vision_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 3274.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.126ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Inference Latency of Trained Model\"\"\"\n",
    "# Inference Latency\n",
    "measure_inference_latency(model=model_trained, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.0.weight:\t409600\n",
      "model.0.0.bias:\t1024\n",
      "model.1.0.weight:\t1048576\n",
      "model.1.0.bias:\t1024\n",
      "model.2.weight:\t10240\n",
      "model.2.bias:\t10\n",
      "Total Parmeter Count in FFNN: 1470474\n",
      "Model Size on Disk: 5.883903 MB\n",
      "Accuracy: 97.430%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count, FLOPs, and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_trained)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_trained, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude pruning on SST2/MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trained Model's architecture\"\"\"\n",
    "print(model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Buffers of Trained Model\"\"\"\n",
    "print(list(model_trained.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN layers:\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get all layers of Trained Model\"\"\"\n",
    "model_layers = get_layers(model=model_trained)\n",
    "print(f\"{model_trained.__class__.__name__} layers:\\n{model_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the first layer:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0661,  0.0115,  0.0095,  ...,  0.0792,  0.0295,  0.0438],\n",
      "        [ 0.0417,  0.0243,  0.0168,  ...,  0.0155,  0.0438,  0.0155],\n",
      "        [ 0.0864,  0.0559,  0.0999,  ...,  0.0503,  0.0688,  0.0363],\n",
      "        ...,\n",
      "        [-0.0159,  0.0330, -0.0122,  ...,  0.0150,  0.0357, -0.0115],\n",
      "        [-0.0207,  0.0613, -0.0179,  ..., -0.0278,  0.0120, -0.0376],\n",
      "        [ 0.0525,  0.0021,  0.0082,  ..., -0.0028,  0.0136,  0.0405]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Bias of the first layer:\n",
      "Parameter containing:\n",
      "tensor([ 0.0228, -0.0110, -0.0333,  ..., -0.0355, -0.0043, -0.0440],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Weight and Bias of the first layer of Trained Model\"\"\"\n",
    "print(f\"Weight of the first layer:\\n{model_layers[0].weight}\")\n",
    "print(f\"Bias of the first layer:\\n{model_layers[0].bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Unstructured Magnitude (L1) Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of Trained Model\"\"\"\n",
    "Sparsity(model_layers=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLinear: 0.0%\n",
      "\tLinear: 0.0%\n",
      "\tLinear: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of Trained Model\"\"\"\n",
    "Sparsity(model_layers=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global Unstructured Pruning\"\"\"\n",
    "global_unstructured_pruning(model=model_trained, sparsity_level=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 99.00001089609484%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "Sparsity(model_layers=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLinear: 97.970947265625%\n",
      "\tLinear: 99.395751953125%\n",
      "\tLinear: 99.638671875%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of pruned Trained Model\"\"\"\n",
    "Sparsity(model_layers=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 11.75825 MB\n",
      "Number of buffers in FFNN: 3\n",
      "Buffers in FFNN:\n",
      "[('model.0.0.weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')), ('model.1.0.weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')), ('model.2.weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check disk size of pruned (before removing mask buffers) Trained Model.\n",
    "You will notice that the model size on disk is doubled after pruning.\n",
    "This is because mask buffers are stored in addition to the original parameters.\"\"\"\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (before removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Number of buffers in FFNN: 0\n",
      "Buffers in FFNN:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "sd = sparse_representation(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (after removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.322601 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save the state dict of Sparse Representation of pruned Trained Model\"\"\"\n",
    "torch.save(sd, \"out/FFNN_weights_pruned.pth\")\n",
    "\n",
    "\"\"\"Notice that the size of this state dict (weights) of pruned Trained Model is quite large.\n",
    "This is because this state dict contains not only tensors as dictionary values but also indices, layouts, etc.\"\"\"\n",
    "print(f'{os.path.getsize(\"out/FFNN_weights_pruned.pth\")/1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLinear: 97.970947265625%\n",
      "\tLinear: 99.395751953125%\n",
      "\tLinear: 99.638671875%\n"
     ]
    }
   ],
   "source": [
    "# load pruned model\n",
    "sd = torch.load(\"out/FFNN_weights_pruned.pth\")\n",
    "model_pruned = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_pruned.load_state_dict({k:(v if v.layout == torch.strided else v.to_dense()) for k,v in sd.items()})\n",
    "Sparsity(model_layers=model_pruned).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "307it [00:00, 3069.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 3542.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.125ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Latency of pruned Trained Model\"\"\"\n",
    "measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.0.weight:\t409600\n",
      "model.0.0.bias:\t1024\n",
      "model.1.0.weight:\t1048576\n",
      "model.1.0.bias:\t1024\n",
      "model.2.weight:\t10240\n",
      "model.2.bias:\t10\n",
      "Total Parmeter Count in FFNN: 1470474\n",
      "Model Size on Disk: 5.883903 MB\n",
      "Accuracy: 10.650%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_pruned)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(model=model_pruned)\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative magnitude pruning (IMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('11767')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bfde7030847683facd11df8195a3943390ddff51b50020d9e445892926ca1a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
