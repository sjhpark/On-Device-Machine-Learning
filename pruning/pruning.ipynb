{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from indiv_utils import load_yaml, size_on_disk, get_layers, \\\n",
    "                        measure_inference_latency, param_count, \\\n",
    "                        FLOPs_count, save_model_weights, start_train, \\\n",
    "                        check_buffers, sparse_representation, Sparsity, \\\n",
    "                        global_unstructured_pruning, accuracy\n",
    "from models import FFNN\n",
    "from data_processing import MNISTDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hyperparameter  | MNIST |\n",
    "| --------------- | ----- |\n",
    "| learning rate   | 0.001 |\n",
    "| batch size      | 64    |\n",
    "| hidden size     | 1024  |\n",
    "| # hidden layers | 2     |\n",
    "| input size      | 20x20 |\n",
    "| output size     | 10    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup\"\"\"\n",
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_hidden = 2\n",
    "hidden_dim = 1024\n",
    "out_dim = 10 # 10 MNIST classes   \n",
    "epochs = 2\n",
    "input_dim = 20*20\n",
    "\n",
    "# config\n",
    "config = load_yaml('config')\n",
    "\n",
    "# device \n",
    "device = torch.device(config['device'])\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model\n",
    "model = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model initialization:\n",
    "Before training, SAVE the model's initial (random) weights. \n",
    "You will use them later for iterative pruning.\"\"\"\n",
    "\n",
    "if os.path.exists(\"out/FFNN_weights_initial.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    initial_random_weights = save_model_weights(model, fname=\"initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "if os.path.exists(\"out/FFNN_weights_trained.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    start_train(model, device, criterion, epochs, batch_size, lr)\n",
    "    trained_weights = save_model_weights(model, fname=\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded initial model weights\n",
      "Loaded trained model weights\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "parsing test features...\n",
      "The number of test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load initial model\"\"\"\n",
    "model_initial = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_initial.load_state_dict(torch.load(\"out/FFNN_weights_initial.pth\"))\n",
    "print(\"Loaded initial model weights\")\n",
    "\n",
    "\"\"\"load trained model\"\"\"\n",
    "model_trained = copy.deepcopy(model_initial)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "print(\"Loaded trained model weights\")\n",
    "\n",
    "\"\"\"test dataset\"\"\"\n",
    "test_dataset = MNISTDataProcessor().vision_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 3712.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.117ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Inference Latency of Trained Model\"\"\"\n",
    "# Inference Latency\n",
    "measure_inference_latency(model=model_trained, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parmeter Count in FFNN: 1470474\n",
      "\tmodel.2.bias:\t10\n",
      "\tmodel.0.0.bias:\t1024\n",
      "\tmodel.1.0.bias:\t1024\n",
      "\tmodel.2.weight:\t10240\n",
      "\tmodel.0.0.weight:\t409600\n",
      "\tmodel.1.0.weight:\t1048576\n",
      "Model Size on Disk: 5.883903 MB\n",
      "Accuracy: 97.430%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count, FLOPs, and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_trained)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_trained, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude pruning on SST2/MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trained Model's architecture\"\"\"\n",
    "print(model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Buffers of Trained Model\"\"\"\n",
    "print(list(model_trained.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN layers:\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get all layers of Trained Model\"\"\"\n",
    "model_layers = get_layers(model=model_trained)\n",
    "print(f\"{model_trained.__class__.__name__} layers:\\n{model_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the first layer:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0661,  0.0115,  0.0095,  ...,  0.0792,  0.0295,  0.0438],\n",
      "        [ 0.0417,  0.0243,  0.0168,  ...,  0.0155,  0.0438,  0.0155],\n",
      "        [ 0.0864,  0.0559,  0.0999,  ...,  0.0503,  0.0688,  0.0363],\n",
      "        ...,\n",
      "        [-0.0159,  0.0330, -0.0122,  ...,  0.0150,  0.0357, -0.0115],\n",
      "        [-0.0207,  0.0613, -0.0179,  ..., -0.0278,  0.0120, -0.0376],\n",
      "        [ 0.0525,  0.0021,  0.0082,  ..., -0.0028,  0.0136,  0.0405]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Bias of the first layer:\n",
      "Parameter containing:\n",
      "tensor([ 0.0228, -0.0110, -0.0333,  ..., -0.0355, -0.0043, -0.0440],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Weight and Bias of the first layer of Trained Model\"\"\"\n",
    "print(f\"Weight of the first layer:\\n{model_layers[0].weight}\")\n",
    "print(f\"Bias of the first layer:\\n{model_layers[0].bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Unstructured Magnitude (L1) Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 0.0%\n",
      "Sparsity of Linear: 0.0%\n",
      "Sparsity of Linear: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global Unstructured Pruning\"\"\"\n",
    "sparsity_level = 0.33\n",
    "global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 32.99998093183403%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of pruned Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 11.75825 MB\n",
      "Number of buffers in FFNN: 3\n",
      "Buffers in FFNN:\n",
      "[('model.0.0.weight_mask', tensor([[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')), ('model.1.0.weight_mask', tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 0., 1., 1.]], device='cuda:0')), ('model.2.weight_mask', tensor([[0., 0., 0.,  ..., 0., 1., 1.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check disk size of pruned (before removing mask buffers) Trained Model.\n",
    "You will notice that the model size on disk is doubled after pruning.\n",
    "This is because mask buffers are stored in addition to the original parameters.\"\"\"\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (before removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Number of buffers in FFNN: 0\n",
      "Buffers in FFNN:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "sd = sparse_representation(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (after removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.705641 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save the state dict of Sparse Representation of pruned Trained Model\"\"\"\n",
    "torch.save(sd, \"out/FFNN_weights_pruned.pth\")\n",
    "\n",
    "\"\"\"Notice that the size of this state dict (weights) of pruned Trained Model is quite large.\n",
    "This is because this state dict contains not only tensors as dictionary values but also indices, layouts, etc.\"\"\"\n",
    "print(f'{os.path.getsize(\"out/FFNN_weights_pruned.pth\")/1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n"
     ]
    }
   ],
   "source": [
    "# load pruned model\n",
    "sd = torch.load(\"out/FFNN_weights_pruned.pth\")\n",
    "model_pruned = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_pruned.load_state_dict({k:(v if v.layout == torch.strided else v.to_dense()) for k,v in sd.items()})\n",
    "Sparsity(model=model_pruned).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 3778.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.122ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Latency of pruned Trained Model\"\"\"\n",
    "measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parmeter Count in FFNN: 1470474\n",
      "\tmodel.2.bias:\t10\n",
      "\tmodel.0.0.bias:\t1024\n",
      "\tmodel.1.0.bias:\t1024\n",
      "\tmodel.2.weight:\t10240\n",
      "\tmodel.0.0.weight:\t409600\n",
      "\tmodel.1.0.weight:\t1048576\n",
      "Model Size on Disk: 19.705641 MB\n",
      "Accuracy: 97.450%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_pruned)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(sd, fname=\"FFNN_weights_pruned.pth\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Global Unstructured Magnitude (L1) Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Pruning 1 =========================\n",
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:00, 1855.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2854.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.197ms\n",
      "Accuracy: 97.450%\n",
      "===================== Pruning 2 =========================\n",
      "Sparsity of Linear: 44.97900390625%\n",
      "Sparsity of Linear: 59.017372131347656%\n",
      "Sparsity of Linear: 60.234375%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [00:00, 2117.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2854.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.199ms\n",
      "Accuracy: 97.420%\n",
      "===================== Pruning 3 =========================\n",
      "Sparsity of Linear: 59.163818359375%\n",
      "Sparsity of Linear: 74.05357360839844%\n",
      "Sparsity of Linear: 77.421875%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:00, 2089.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2984.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.189ms\n",
      "Accuracy: 96.950%\n",
      "===================== Pruning 4 =========================\n",
      "Sparsity of Linear: 70.3134765625%\n",
      "Sparsity of Linear: 83.50811004638672%\n",
      "Sparsity of Linear: 86.5625%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [00:00, 2179.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2936.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.192ms\n",
      "Accuracy: 95.780%\n",
      "===================== Pruning 5 =========================\n",
      "Sparsity of Linear: 78.751220703125%\n",
      "Sparsity of Linear: 89.47248458862305%\n",
      "Sparsity of Linear: 91.89453125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [00:00, 2173.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2928.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.194ms\n",
      "Accuracy: 91.760%\n",
      "===================== Pruning 6 =========================\n",
      "Sparsity of Linear: 84.992919921875%\n",
      "Sparsity of Linear: 93.24560165405273%\n",
      "Sparsity of Linear: 94.765625%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:00, 1878.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2836.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.200ms\n",
      "Accuracy: 88.840%\n",
      "===================== Pruning 7 =========================\n",
      "Sparsity of Linear: 89.51513671875%\n",
      "Sparsity of Linear: 95.63865661621094%\n",
      "Sparsity of Linear: 96.89453125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174it [00:00, 1739.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2605.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.220ms\n",
      "Accuracy: 66.400%\n",
      "===================== Pruning 8 =========================\n",
      "Sparsity of Linear: 92.722412109375%\n",
      "Sparsity of Linear: 97.17588424682617%\n",
      "Sparsity of Linear: 97.998046875%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198it [00:00, 1974.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2654.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.219ms\n",
      "Accuracy: 25.620%\n",
      "===================== Pruning 9 =========================\n",
      "Sparsity of Linear: 94.9443359375%\n",
      "Sparsity of Linear: 98.17686080932617%\n",
      "Sparsity of Linear: 98.779296875%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:00, 1998.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2661.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.216ms\n",
      "Accuracy: 23.110%\n",
      "===================== Pruning 10 =========================\n",
      "Sparsity of Linear: 96.50244140625%\n",
      "Sparsity of Linear: 98.82183074951172%\n",
      "Sparsity of Linear: 99.16015625%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:00, 1985.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2668.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.215ms\n",
      "Accuracy: 17.040%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load trained moel\"\"\"\n",
    "model_trained = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "\n",
    "\"\"\"Repeated Global Unstructured Magnitude Pruning\"\"\"\n",
    "for i in range(10):\n",
    "\n",
    "    print(f\"===================== Pruning {i+1} =========================\")\n",
    "    \n",
    "    \"\"\"Global Unstructured Pruning\"\"\"\n",
    "    sparsity_level = 0.33\n",
    "    global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)\n",
    "\n",
    "    \"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "    Sparsity(model_trained).each_layer()\n",
    "    \n",
    "    # \"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "    # sd = sparse_representation(model=model_trained)\n",
    "\n",
    "    # model_pruned = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "    # model_pruned.load_state_dict({k:(v if v.layout == torch.strided else v.to_dense()) for k,v in sd.items()})\n",
    "\n",
    "    model_pruned = model_trained\n",
    "    \n",
    "    \"\"\"Latency of pruned Trained Model\"\"\"\n",
    "    measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Pruning 1 =========================\n",
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 19.705641 MB\n",
      "===================== Pruning 2 =========================\n",
      "Sparsity of Linear: 44.97900390625%\n",
      "Sparsity of Linear: 59.017372131347656%\n",
      "Sparsity of Linear: 60.234375%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 13.212329 MB\n",
      "===================== Pruning 3 =========================\n",
      "Sparsity of Linear: 59.163818359375%\n",
      "Sparsity of Linear: 74.05357360839844%\n",
      "Sparsity of Linear: 77.421875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 8.861865 MB\n",
      "===================== Pruning 4 =========================\n",
      "Sparsity of Linear: 70.3134765625%\n",
      "Sparsity of Linear: 83.50811004638672%\n",
      "Sparsity of Linear: 86.5625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 5.946985 MB\n",
      "===================== Pruning 5 =========================\n",
      "Sparsity of Linear: 78.7509765625%\n",
      "Sparsity of Linear: 89.47248458862305%\n",
      "Sparsity of Linear: 91.89453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 3.994025 MB\n",
      "===================== Pruning 6 =========================\n",
      "Sparsity of Linear: 84.992919921875%\n",
      "Sparsity of Linear: 93.2455062866211%\n",
      "Sparsity of Linear: 94.765625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 2.685481 MB\n",
      "===================== Pruning 7 =========================\n",
      "Sparsity of Linear: 89.51513671875%\n",
      "Sparsity of Linear: 95.63865661621094%\n",
      "Sparsity of Linear: 96.89453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 1.808873 MB\n",
      "===================== Pruning 8 =========================\n",
      "Sparsity of Linear: 92.72216796875%\n",
      "Sparsity of Linear: 97.17588424682617%\n",
      "Sparsity of Linear: 97.998046875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 1.221417 MB\n",
      "===================== Pruning 9 =========================\n",
      "Sparsity of Linear: 94.944091796875%\n",
      "Sparsity of Linear: 98.17686080932617%\n",
      "Sparsity of Linear: 98.779296875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 0.827881 MB\n",
      "===================== Pruning 10 =========================\n",
      "Sparsity of Linear: 96.502197265625%\n",
      "Sparsity of Linear: 98.82183074951172%\n",
      "Sparsity of Linear: 99.16015625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 0.564201 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mimicking pruned model size on disk over iterative pruning.\n",
    "This is a workaround since copy.deepcopy() does not work for PyTorch's pruned model.\"\"\"\n",
    "sparsity_level = 0.33\n",
    "for i in range(10):\n",
    "    print(f\"===================== Pruning {i+1} =========================\")\n",
    "    \n",
    "    \"\"\"load trained moel\"\"\"\n",
    "    model_trained = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "    model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "    \n",
    "    \"\"\"Global Unstructured Pruning\"\"\"\n",
    "    global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)\n",
    "    sparsity_level = (1 - sparsity_level) * 0.33 + sparsity_level\n",
    "\n",
    "    \"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "    Sparsity(model_trained).each_layer()\n",
    "    \n",
    "    \"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "    sd = sparse_representation(model=model_trained)\n",
    "\n",
    "    torch.save(sd, \"out/FFNN_weights_pruned.pth\")\n",
    "    \n",
    "    # Disk Storage\n",
    "    size_on_disk(sd, fname=\"FFNN_weights_pruned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative magnitude pruning (IMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('11767')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bfde7030847683facd11df8195a3943390ddff51b50020d9e445892926ca1a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
