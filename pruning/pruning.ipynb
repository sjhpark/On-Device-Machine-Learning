{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from indiv_utils import load_yaml, size_on_disk, get_layers, \\\n",
    "                        measure_inference_latency, param_count, \\\n",
    "                        FLOPs_count, save_model_weights, start_train, \\\n",
    "                        check_buffers, sparse_representation, Sparsity, \\\n",
    "                        global_unstructured_pruning, accuracy\n",
    "from models import FFNN\n",
    "from data_processing import MNISTDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| hyperparameter  | MNIST |\n",
    "| --------------- | ----- |\n",
    "| learning rate   | 0.001 |\n",
    "| batch size      | 64    |\n",
    "| hidden size     | 1024  |\n",
    "| # hidden layers | 2     |\n",
    "| input size      | 20x20 |\n",
    "| output size     | 10    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup\"\"\"\n",
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_hidden = 2\n",
    "hidden_dim = 1024\n",
    "out_dim = 10 # 10 MNIST classes   \n",
    "epochs = 2\n",
    "input_dim = 20*20\n",
    "\n",
    "# config\n",
    "config = load_yaml('config')\n",
    "\n",
    "# device \n",
    "device = torch.device(config['device'])\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model\n",
    "model = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model initialization:\n",
    "Before training, SAVE the model's initial (random) weights. \n",
    "You will use them later for iterative pruning.\"\"\"\n",
    "\n",
    "if os.path.exists(\"out/FFNN_weights_initial.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    initial_random_weights = save_model_weights(model, fname=\"initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "if os.path.exists(\"out/FFNN_weights_trained.pth\"):\n",
    "    pass\n",
    "else:\n",
    "    start_train(model, device, criterion, epochs, batch_size, lr)\n",
    "    trained_weights = save_model_weights(model, fname=\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded initial model weights\n",
      "Loaded trained model weights\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "Center Cropping images from 28x28 to 20x20\n",
      "new image size:  (400,)\n",
      "parsing test features...\n",
      "The number of test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load initial model\"\"\"\n",
    "model_initial = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_initial.load_state_dict(torch.load(\"out/FFNN_weights_initial.pth\"))\n",
    "print(\"Loaded initial model weights\")\n",
    "\n",
    "\"\"\"load trained model\"\"\"\n",
    "model_trained = copy.deepcopy(model_initial)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "print(\"Loaded trained model weights\")\n",
    "\n",
    "\"\"\"test dataset\"\"\"\n",
    "test_dataset = MNISTDataProcessor().vision_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 3735.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.113ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Inference Latency of Trained Model\"\"\"\n",
    "# Inference Latency\n",
    "measure_inference_latency(model=model_trained, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parmeter Count in FFNN: 1470474\n",
      "\tmodel.2.bias:\t10\n",
      "\tmodel.0.0.bias:\t1024\n",
      "\tmodel.1.0.bias:\t1024\n",
      "\tmodel.2.weight:\t10240\n",
      "\tmodel.0.0.weight:\t409600\n",
      "\tmodel.1.0.weight:\t1048576\n",
      "Model Size on Disk: 5.883903 MB\n",
      "Accuracy: 97.430%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count, FLOPs, and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_trained)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_trained, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude pruning on SST2/MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trained Model's architecture\"\"\"\n",
    "print(model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Buffers of Trained Model\"\"\"\n",
    "print(list(model_trained.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN layers:\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=400, out_features=1024, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get all layers of Trained Model\"\"\"\n",
    "model_layers = get_layers(model=model_trained)\n",
    "print(f\"{model_trained.__class__.__name__} layers:\\n{model_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the first layer:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0661,  0.0115,  0.0095,  ...,  0.0792,  0.0295,  0.0438],\n",
      "        [ 0.0417,  0.0243,  0.0168,  ...,  0.0155,  0.0438,  0.0155],\n",
      "        [ 0.0864,  0.0559,  0.0999,  ...,  0.0503,  0.0688,  0.0363],\n",
      "        ...,\n",
      "        [-0.0159,  0.0330, -0.0122,  ...,  0.0150,  0.0357, -0.0115],\n",
      "        [-0.0207,  0.0613, -0.0179,  ..., -0.0278,  0.0120, -0.0376],\n",
      "        [ 0.0525,  0.0021,  0.0082,  ..., -0.0028,  0.0136,  0.0405]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Bias of the first layer:\n",
      "Parameter containing:\n",
      "tensor([ 0.0228, -0.0110, -0.0333,  ..., -0.0355, -0.0043, -0.0440],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Weight and Bias of the first layer of Trained Model\"\"\"\n",
    "print(f\"Weight of the first layer:\\n{model_layers[0].weight}\")\n",
    "print(f\"Bias of the first layer:\\n{model_layers[0].bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Unstructured Magnitude (L1) Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 0.0%\n",
      "Sparsity of Linear: 0.0%\n",
      "Sparsity of Linear: 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global Unstructured Pruning\"\"\"\n",
    "sparsity_level = 0.33\n",
    "global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 32.99998093183403%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).global_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sparsity of each layer of pruned Trained Model\"\"\"\n",
    "Sparsity(model=model_trained).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 11.75825 MB\n",
      "Number of buffers in FFNN: 3\n",
      "Buffers in FFNN:\n",
      "[('model.0.0.weight_mask', tensor([[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')), ('model.1.0.weight_mask', tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 0., 1., 1.]], device='cuda:0')), ('model.2.weight_mask', tensor([[0., 0., 0.,  ..., 0., 1., 1.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check disk size of pruned (before removing mask buffers) Trained Model.\n",
    "You will notice that the model size on disk is doubled after pruning.\n",
    "This is because mask buffers are stored in addition to the original parameters.\"\"\"\n",
    "size_on_disk(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (before removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Number of buffers in FFNN: 0\n",
      "Buffers in FFNN:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "sd = sparse_representation(model=model_trained)\n",
    "\n",
    "\"\"\"Buffers in pruned (after removing mask buffers) Trained Model\"\"\"\n",
    "check_buffers(model=model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.705641 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save the state dict of Sparse Representation of pruned Trained Model\"\"\"\n",
    "torch.save(sd, \"out/FFNN_weights_pruned.pth\")\n",
    "\n",
    "\"\"\"Notice that the size of this state dict (weights) of pruned Trained Model is quite large.\n",
    "This is because this state dict contains not only tensors as dictionary values but also indices, layouts, etc.\"\"\"\n",
    "print(f'{os.path.getsize(\"out/FFNN_weights_pruned.pth\")/1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n"
     ]
    }
   ],
   "source": [
    "# load pruned model\n",
    "sd = torch.load(\"out/FFNN_weights_pruned.pth\")\n",
    "model_pruned = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_pruned.load_state_dict({k:(v if v.layout == torch.strided else v.to_dense()) for k,v in sd.items()})\n",
    "Sparsity(model=model_pruned).each_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 3848.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.116ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Latency of pruned Trained Model\"\"\"\n",
    "measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parmeter Count in FFNN: 1470474\n",
      "\tmodel.2.bias:\t10\n",
      "\tmodel.0.0.bias:\t1024\n",
      "\tmodel.1.0.bias:\t1024\n",
      "\tmodel.2.weight:\t10240\n",
      "\tmodel.0.0.weight:\t409600\n",
      "\tmodel.1.0.weight:\t1048576\n",
      "Model Size on Disk: 19.705641 MB\n",
      "Accuracy: 97.450%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parameter Count and Disk Storage of Trained Model\"\"\"\n",
    "# Parameter Count\n",
    "param_count(model=model_pruned)\n",
    "\n",
    "# Disk Storage\n",
    "size_on_disk(sd, fname=\"FFNN_weights_pruned.pth\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Global Unstructured Magnitude (L1) Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Pruning 1 =========================\n",
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [00:00, 1829.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2602.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.210ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m measure_inference_latency(model\u001b[39m=\u001b[39mmodel_pruned, test_dataset\u001b[39m=\u001b[39mtest_dataset, device\u001b[39m=\u001b[39mdevice, warmup_itr\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Accuracy\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m accuracy(model\u001b[39m=\u001b[39;49mmodel_pruned, test_dataset\u001b[39m=\u001b[39;49mtest_dataset, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Fall2023/11767/On-Device-Machine-Learning/pruning/indiv_utils.py:173\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(model, test_dataset, device)\u001b[0m\n\u001b[1;32m    171\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    172\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 173\u001b[0m outputs \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m    174\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    175\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Fall2023/11767/On-Device-Machine-Learning/pruning/models.py:26\u001b[0m, in \u001b[0;36mFFNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1523\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mforward pre-hook must return None or a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1524\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m             )\n\u001b[1;32m   1526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, args)\n\u001b[1;32m   1528\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1529\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/utils/prune.py:33\u001b[0m, in \u001b[0;36mBasePruningMethod.__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, module, inputs):\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Multiplies the mask (stored in ``module[name + '_mask']``)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    into the original tensor (stored in ``module[name + '_orig']``)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m    and stores the result into ``module[name]`` by using\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m        inputs: not used.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[39msetattr\u001b[39;49m(module, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensor_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_mask(module))\n",
      "File \u001b[0;32m~/anaconda3/envs/11767/lib/python3.10/site-packages/torch/nn/modules/module.py:1674\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     buffers[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1673\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1674\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"load trained moel\"\"\"\n",
    "model_trained = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "\n",
    "\"\"\"Repeated Global Unstructured Magnitude Pruning\"\"\"\n",
    "for i in range(10):\n",
    "\n",
    "    print(f\"===================== Pruning {i+1} =========================\")\n",
    "    \n",
    "    \"\"\"Global Unstructured Pruning\"\"\"\n",
    "    sparsity_level = 0.33\n",
    "    global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)\n",
    "\n",
    "    \"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "    Sparsity(model_trained).each_layer()\n",
    "    \n",
    "    # \"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "    # sd = sparse_representation(model=model_trained)\n",
    "\n",
    "    # model_pruned = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "    # model_pruned.load_state_dict({k:(v if v.layout == torch.strided else v.to_dense()) for k,v in sd.items()})\n",
    "\n",
    "    model_pruned = model_trained\n",
    "    \n",
    "    \"\"\"Latency of pruned Trained Model\"\"\"\n",
    "    measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Pruning 1 =========================\n",
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 19.705641 MB\n",
      "===================== Pruning 2 =========================\n",
      "Sparsity of Linear: 44.97900390625%\n",
      "Sparsity of Linear: 59.017372131347656%\n",
      "Sparsity of Linear: 60.234375%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 13.212329 MB\n",
      "===================== Pruning 3 =========================\n",
      "Sparsity of Linear: 59.163818359375%\n",
      "Sparsity of Linear: 74.05357360839844%\n",
      "Sparsity of Linear: 77.421875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 8.861865 MB\n",
      "===================== Pruning 4 =========================\n",
      "Sparsity of Linear: 70.3134765625%\n",
      "Sparsity of Linear: 83.50811004638672%\n",
      "Sparsity of Linear: 86.5625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 5.946985 MB\n",
      "===================== Pruning 5 =========================\n",
      "Sparsity of Linear: 78.7509765625%\n",
      "Sparsity of Linear: 89.47248458862305%\n",
      "Sparsity of Linear: 91.89453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 3.994025 MB\n",
      "===================== Pruning 6 =========================\n",
      "Sparsity of Linear: 84.992919921875%\n",
      "Sparsity of Linear: 93.2455062866211%\n",
      "Sparsity of Linear: 94.765625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 2.685481 MB\n",
      "===================== Pruning 7 =========================\n",
      "Sparsity of Linear: 89.51513671875%\n",
      "Sparsity of Linear: 95.63865661621094%\n",
      "Sparsity of Linear: 96.89453125%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 1.808873 MB\n",
      "===================== Pruning 8 =========================\n",
      "Sparsity of Linear: 92.72216796875%\n",
      "Sparsity of Linear: 97.17588424682617%\n",
      "Sparsity of Linear: 97.998046875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 1.221417 MB\n",
      "===================== Pruning 9 =========================\n",
      "Sparsity of Linear: 94.944091796875%\n",
      "Sparsity of Linear: 98.17686080932617%\n",
      "Sparsity of Linear: 98.779296875%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 0.827881 MB\n",
      "===================== Pruning 10 =========================\n",
      "Sparsity of Linear: 96.502197265625%\n",
      "Sparsity of Linear: 98.82183074951172%\n",
      "Sparsity of Linear: 99.16015625%\n",
      "sparsifying model.0.0.weight\n",
      "sparsifying model.1.0.weight\n",
      "sparsifying model.2.weight\n",
      "Model Size on Disk: 0.564201 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mimicking pruned model size on disk over iterative pruning.\n",
    "This is a workaround since copy.deepcopy() does not work for PyTorch's pruned model.\"\"\"\n",
    "sparsity_level = 0.33\n",
    "for i in range(10):\n",
    "    print(f\"===================== Pruning {i+1} =========================\")\n",
    "    \n",
    "    \"\"\"load trained moel\"\"\"\n",
    "    model_trained = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "    model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "    \n",
    "    \"\"\"Global Unstructured Pruning\"\"\"\n",
    "    global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)\n",
    "    sparsity_level = (1 - sparsity_level) * 0.33 + sparsity_level\n",
    "\n",
    "    \"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "    Sparsity(model_trained).each_layer()\n",
    "    \n",
    "    \"\"\"State Dict of Spare Representation of pruned Trained Model\"\"\"\n",
    "    sd = sparse_representation(model=model_trained)\n",
    "\n",
    "    torch.save(sd, \"out/FFNN_weights_pruned.pth\")\n",
    "    \n",
    "    # Disk Storage\n",
    "    size_on_disk(sd, fname=\"FFNN_weights_pruned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative magnitude pruning (IMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Pruning 1 =========================\n",
      "Sparsity of Linear: 26.169677734375%\n",
      "Sparsity of Linear: 35.65034866333008%\n",
      "Sparsity of Linear: 34.814453125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [00:00, 1714.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2705.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.196ms\n",
      "Accuracy: 83.570%\n",
      "===================== Pruning 2 =========================\n",
      "Sparsity of Linear: 43.27001953125%\n",
      "Sparsity of Linear: 59.73625183105469%\n",
      "Sparsity of Linear: 54.98046875%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "185it [00:00, 1849.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2631.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.206ms\n",
      "Accuracy: 83.950%\n",
      "===================== Pruning 3 =========================\n",
      "Sparsity of Linear: 53.95361328125%\n",
      "Sparsity of Linear: 76.13353729248047%\n",
      "Sparsity of Linear: 72.841796875%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [00:00, 1747.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2621.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.207ms\n",
      "Accuracy: 81.190%\n",
      "===================== Pruning 4 =========================\n",
      "Sparsity of Linear: 60.810546875%\n",
      "Sparsity of Linear: 87.2304916381836%\n",
      "Sparsity of Linear: 85.5078125%\n",
      "Measuring inference latency of trained FFNN on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:00, 1865.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2597.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference latency: 0.209ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m measure_inference_latency(model\u001b[39m=\u001b[39mmodel_pruned, test_dataset\u001b[39m=\u001b[39mtest_dataset, device\u001b[39m=\u001b[39mdevice, warmup_itr\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39m# Accuracy\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m accuracy(model\u001b[39m=\u001b[39;49mmodel_pruned, test_dataset\u001b[39m=\u001b[39;49mtest_dataset, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Fall2023/11767/On-Device-Machine-Learning/pruning/indiv_utils.py:175\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(model, test_dataset, device)\u001b[0m\n\u001b[1;32m    173\u001b[0m     outputs \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m    174\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39;49m labels)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    176\u001b[0m acc \u001b[39m=\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_dataloader\u001b[39m.\u001b[39mdataset) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"load trained moel\"\"\"\n",
    "model_trained = FFNN(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim, num_hidden=num_hidden, bias=True).to(device)\n",
    "model_trained.load_state_dict(torch.load(\"out/FFNN_weights_trained.pth\"))\n",
    "\n",
    "\"\"\"Repeated Global Unstructured Magnitude Pruning\"\"\"\n",
    "for i in range(10):\n",
    "\n",
    "    print(f\"===================== Pruning {i+1} =========================\")\n",
    "    \n",
    "    \"\"\"Global Unstructured Pruning\"\"\"\n",
    "    sparsity_level = 0.33\n",
    "    global_unstructured_pruning(model=model_trained, sparsity_level=sparsity_level)\n",
    "\n",
    "    \"\"\"Sparsity of pruned Trained Model\"\"\"\n",
    "    Sparsity(model_trained).each_layer()\n",
    "\n",
    "    init_weights = torch.load(\"out/FFNN_weights_initial.pth\")\n",
    "    prune_param_list = [(model_trained.model[0][0], 'weight'),\n",
    "                        (model_trained.model[1][0], 'weight'),\n",
    "                        (model_trained.model[2], 'weight')]\n",
    "    init_updated = {k + (\"_orig\" if \"weight\" in k else \"\"):v for k,v in init_weights.items()}\n",
    "    model_trained_sd = model_trained.state_dict()\n",
    "    model_trained_sd.update(init_updated)\n",
    "    model_trained.load_state_dict(model_trained_sd)\n",
    "\n",
    "    model_pruned = model_trained\n",
    "    \n",
    "    \"\"\"Latency of pruned Trained Model\"\"\"\n",
    "    measure_inference_latency(model=model_pruned, test_dataset=test_dataset, device=device, warmup_itr=100)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy(model=model_pruned, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('11767')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bfde7030847683facd11df8195a3943390ddff51b50020d9e445892926ca1a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
